---
layout: post
title: "Roadmap for Implementing Modular Neural Networks Agents"
tags: research machine-learning
category: modular-neural-networks
---
In a previous post, a design was proposed for how agents could be implemented
to solve the matrix transposition challenge. The proposed design would be
implementable using a set of classically implemented components, which would
then be augmented with machine learning components. This post will outline the
plan for the various stages of implementation.

## Phase 1: From Humble Beginnings
The first step for this project will be to implement the foundation that the
rest of the project will build off of. This will entail implementing the main
simulation components, the command line interface used to run agents, and a
basic set of components that can be used to implement an agent.

The core simulation components implemented during this phase will mirror the
components implemented for the Matrix Cache Simulator demo, but will be
implemented in C# instead of TypeScript. Additionally, the interface that agents
will use to interact with the components will be different. This is because
agents will have access to a limited set of registers that can be used to store
data without affecting cache lines, and agents are given additional feedback
about the effects of their actions.

> C# was chosen as the language to use for this project since it's my favorite
> programming language and it has support for Torch via [TorchSharp](https://github.com/dotnet/TorchSharp),
> which is supported by the .NET Foundation.

The decision to introduce registers into the simulation was made because
the use of registers can allow for more optimal solutions to the matrix
transposition problem. For example, with certain cache configurations and matrix
sizes, a transpose algorithm that operates on blocks within the matrix performs
worse when transposing specific blocks. This is because the blocks that are
being transposed map to the same set of cache lines, thus reducing the cache's
effective capacity. By storing certain values in registers and not writing them
to memory immediately, agents can avoid evicting a cache line that will then be
loaded again on when the next matrix cell is processed.

> Want to see this effect in action? Check out the [Matrix Cache Simulator demo]({% post_url MatrixCacheSim/2023-06-17-matrix-cache-simulator-demo %})
> and run the cache friendly algorithm using the default settings for the demo.
> In this configuration, the matrix will be subdivided into a 4x4 set of
> blocks, where each block is an 8x8 set of cells in the matrix. When the
> algorithm processes blocks in the first and third block-level columns or
> the second and fourth block-level columns, you'll see additional cache misses
> since cache lines in those specific pairs of columns map to the same cache
> cache set.
> 
> This effect occurs because the size of the set of cache lines that both
> columns map to isn't big enough to store all the memory addresses for the two
> blocks the algorithm iterates over. As a result, certain memory addresses will
> cause a cache line to be evicted when the algorithm performs a write, only for
> the next read operation to load the same cache line again. If you re-run the
> simulation with the same settings but with the cache associativity set to
> "Fully Associative", this effect will go away since the cache will be
> organized as a single set of cache lines.
{: .prompt-tip }

For this initial phase, the command line interface will only need to support
setting up and running an agent against a variety of scenarios. The agent's
results for the various scenarios will then be reported and used for comparing
the performance of different agents. Additional commands will be added to the
CLI in later phases to support training specific components by running them
against a set of scenarios.

## Phase 2: The First Agents
Once the simulation components are in place and interfaces for agents have been
defined, the next step will be to implement the first agents. During this phase,
the framework for agents will be added and several purely classical agents will
be implemented.

Classes will be added that allow agents to be quickly implemented using the
three layer design proposed in the [previous post]({% post_url Research/ModularNeuralNetworks/2023-07-09-initial-design %}).
These classes will provide the basic functionality common to all agents, such
as allowing components to be added to a layer and merging output from a layer's
components into a single vector for the next layer to consume.

After implementing the framework, a few simple agents will be implemented. One
such agent will implement the naive transposition algorithm, while another
will implement the cache optimized block transposition algorithm. Both of these
algorithms are featured in the matrix cache simulator demo, and neither
agent will make use of feedback from the simulator on whether a particular
action caused a cache miss or not.

Lastly, the CLI will be updated to produce replay files. These files will be
JSON-formatted files containing the actions taken by an agent. Each action will
be saved in the same format as the actions recorded during playback of an
algorithm in the matrix cache simulator. This will allow these playback files
to be loaded and replayed on this blog, allowing viewers to visually see how
an agent performs.

## Phase 3: The First Learners
Once the CLI has end-to-end support for classical agents, a few additional
agents will be implemented. These agents will continue to be purely classical
agents, but will attempt to determine the current cache configuration in use by
a simulation run and tailor their actions to that configuration. This should
result in a performance improvement over the agents implemented in the previous
stage, especially on larger matrices where the agent has more time to make use
of learned information.

## Phase 4: Enabling Automated Learning
The next step will be to add support for training neural network components.
The goal of the modular neural network design is to allow agents to be
implemented not as a monolithic neural network, but as a collection of smaller
neural networks that can be trained independently and used as independent
components of a larger agent. As such, the CLI will need to be updated to allow
network-based components to trained by running a simulation and then updating
the weights of the network-based on the results of the simulation. Notably,
these runs will generally not expect the agent to be able to transpose the
matrix, but will instead be used to train the component to perform its specific
task.

Once support for training has been added, a few network-based components will be
implemented and used to test out some additional agents. These components will
all be part of the input layer and will be network-based implementations of
components previously implemented in phase 3. Next, the agents introduced in
phase 3 will be duplicated, where each duplicated agent uses the same design
regarding the components it uses, but classical components will be replaced with
the new network-based components.

## Phase 5: Network-Based Decision Making
Once it's been proven that network components can be used in the input layer,
the next step will be to introduce network-based components to the decision
layer. This will allow networks to be trained to implement the matrix
transposition algorithm itself rather than just augmenting input data with
additional information.

By the end of this phase, it should be possible to implement a purely
network-based agent that can transpose matrices. The current expectation is that
purely network-based agents will likely perform worse than hybrid agents;
however, it's also possible that a purely network-based agent will be on par or
better than classical/hybrid agents. In this case, the only downside of a purely
network-based agent will be the increased training time.

## Phase 6: Increasing Network Complexity
The network-based components implemented in the previous phases are expected
to be of limited complexity so that training the networks takes less time. Once
both input and decision layer components have been implemented using neural
networks though, the next step will be to increase the complexity of the
networks used in components to see how agent performance can be improved.

Network components implemented during this phase will likely begin to overfit
to the specific scenarios that they are trained on due to the increased
complexity of the networks. Ideally, at the end of this phase, agents can pick
from classical components, underfitting network components, overfitting network
components, and generalizable network components.

## Phase 7: Component Synthesis
The final phase of this project will lay the ground work for future projects
that research additional implementations and/or capabilities that may be
possible using modular neural networks. The goal of this phase will be to allow
agents to generate and add their own modules during training. This will allow
agents to experiment with new components and add them to their input/decision
layer as needed.

In order to implement such a capability, I expect that the CLI will need to be
updated to allow a training session to be suspended temporarily and a new
training session started using parameters generated by the agent. The agent will
then need to provide both a component to be trained and a way to score the
component's performance. This will allow the CLI to train the component to some
threshold, then return the component to the agent and resume the original
training process. The original training process can then make use of the extra
data from the new component and hopefully improve.

While I definitely am not sure how this capability can be implemented, I do have
a few ideas. Notably, I'm curious as to whether the design used for generative
adversarial networks could be adapted in some way to an asymmetric scenario
where a network only exists on one side of the equation. Alternatively, perhaps
it may require training a separate network or set of classical components to
monitor the agent's components and trigger the generation of new sets of
components.

This phase is highly experimental and will definitely require a lot of
experimentation and iteration to get working, even at a basic level. However,
finding a way to implement this capability would be a massive step for the
development of more complex modular agents where it may not always be possible
or feasible to manually implement components for the agent.

## What's Next?
There are a few other ideas I've had for how modular neural networks can be
implemented in the future that I'd like to touch on briefly. These ideas are
highly experimental ideas that may or may not pan out, but they're areas that
I want to experiment with in the future. This next post will likely be the
final "introductory" post in this series.

> Find the next post in this series [here]({% post_url Research/ModularNeuralNetworks/2023-07-18-future-experiments %})

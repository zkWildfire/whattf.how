import { ILlm } from "../LLMs/Llm";
import { IConversation } from "./Conversation";
import { IMessage } from "../Messages/Message";
import { EventDispatcher, IEvent } from "strongly-typed-events";
import { IApiKeyProvider } from "../../Auth/ApiKeyProvider";
import assert from "assert";
import { ERole } from "../Role";
import { IPrompt } from "../Prompts/Prompt";
import { LlmMessage } from "../Messages/LlmMessage";

/// Conversation implementation only used for testing.
/// This conversation implementation only allows for a single linear
///   conversation path and does not support branching. The functionality of
///   this class is approximately equivalent to that of the default ChatGPT
///   web interface.
export class LinearConversation implements IConversation
{
	/// Event broadcast to when a message is sent to the LLM.
	/// The event arguments will be the conversation that the sent message is
	///   part of and the message that was sent.
	get OnMessageSent(): IEvent<IConversation, IMessage>
	{
		return this._onMessageSent.asEvent();
	}

	/// Event broadcast to when a response is received from the LLM.
	/// The event arguments will be the conversation that the received message
	///   is for and the message that was received.
	get OnResponseReceived(): IEvent<IConversation, IMessage>
	{
		return this._onResponseReceived.asEvent();
	}

	/// User-assigned name of the conversation.
	get Name(): string
	{
		return this._name;
	}

	/// LLM used by the conversation.
	get ILlm(): ILlm
	{
		return this._llm;
	}

	/// Root message of the conversation.
	get RootMessage(): IMessage
	{
		return this._rootMessage;
	}

	/// All leaf messages in the conversation.
	get LeafMessages(): IMessage[]
	{
		return [this._currentLeafMessage];
	}

	/// Total number of messages in the conversation.
	get MessageCount(): number
	{
		// Walk backwards through the conversation tree and count the number of
		//   messages
		// This isn't very efficient, but this class is only used for testing
		//   so it doesn't really matter
		let messageCount = 0;
		let currentMessage: IMessage | null = this._currentLeafMessage;
		while (currentMessage !== null)
		{
			messageCount++;
			currentMessage = currentMessage.Parent;
		}

		return messageCount;
	}

	/// Total cost incurred by sending tokens to the LLM.
	/// @warning "Outbound" here refers to messages sent to the LLM, which
	///   corresponds to the "inbound" cost of the LLM.
	get OutboundCost(): number
	{
		// Since this property only considers the outbound cost, use a cost of
		//   0 for tokens generated by the LLM
		return this.CalcCost(new Map<ERole, number>([
			[ERole.Assistant, 0],
			[ERole.System, this._llm.OutboundCost],
			[ERole.User, this._llm.OutboundCost]
		]));
	}

	/// Total cost incurred by receiving tokens from the LLM.
	/// @warning "Inbound" here refers to messages received from the LLM, which
	///   corresponds to the "outbound" cost of the LLM.
	get InboundCost(): number
	{
		// Since this property only considers the inbound cost, use a cost of
		//   0 for tokens sent to the LLM
		return this.CalcCost(new Map<ERole, number>([
			[ERole.Assistant, this._llm.InboundCost],
			[ERole.System, 0],
			[ERole.User, 0]
		]));
	}

	/// Total cost of the conversation in dollars.
	get TotalCost(): number
	{
		return this.OutboundCost + this.InboundCost;
	}

	/// Event backing the `OnMessageSent` property.
	private readonly _onMessageSent =
		new EventDispatcher<IConversation, IMessage>();

	/// Event backing the `OnResponseReceived` property.
	private readonly _onResponseReceived =
		new EventDispatcher<IConversation, IMessage>();

	/// Name assigned to the conversation.
	private readonly _name: string;

	/// LLM used by the conversation.
	private readonly _llm: ILlm;

	/// Root message of the conversation.
	private readonly _rootMessage: IMessage;

	/// Service used to get the API key to use when sending messages to the LLM.
	private readonly _apiKeyProvider: IApiKeyProvider;

	/// Number of tokens to aim for in each prompt sent to the LLM.
	private readonly _targetPromptTokenCount: number;

	/// Current leaf message in the conversation.
	private _currentLeafMessage: IMessage;

	/// Initializes the conversation.
	/// @param name Name assigned to the conversation.
	/// @param llm LLM used by the conversation.
	/// @param rootMessage Root message of the conversation.
	/// @param apiKeyProvider API key provider used to get the API key to use
	///   when sending messages to the LLM.
	/// @param targetPromptTokenCount Number of tokens to target for each prompt
	///   sent to the LLM. Increasing this value will increase the amount of
	///   context that the LLM receives but will decrease the number of tokens
	///   available for output and will increase the cost of the conversation.
	constructor(
		name: string,
		llm: ILlm,
		rootMessage: IMessage,
		apiKeyProvider: IApiKeyProvider,
		targetPromptTokenCount: number)
	{
		this._name = name;
		this._llm = llm;
		this._rootMessage = rootMessage;
		this._apiKeyProvider = apiKeyProvider;
		this._targetPromptTokenCount = targetPromptTokenCount;
		this._currentLeafMessage = rootMessage;
	}

	/// Adds a new message to the conversation without sending it to the LLM.
	/// This is intended for adding initial messages used to start the
	///   conversation. However, it could also be used to add messages in the
	///   middle of conversations if necessary.
	/// @param message Message to add. Must have a known actual token count.
	/// @warning Messages sent via this method will never trigger the
	///   on message sent or on message received events.
	public AppendMessage(message: IMessage): void
	{
		assert(message.MessageTokenCountActual !== -1);

		// Make sure the message is a child of the current leaf message
		assert(message.Parent === this._currentLeafMessage);

		// Update the current leaf message
		this._currentLeafMessage = message;
	}

	/// Sends a message to the LLM.
	/// This will also add new messages to the conversation.
	/// @param message Message to send.
	/// @returns The message that was received from the LLM.
	public async SendMessage(message: IMessage): Promise<IMessage>
	{
		assert(message.Role === ERole.User, "Only user messages can be sent");

		// Walk backwards through the current thread until the target number of
		//   tokens is met for the prompt
		let promptTokens = message.MessageTokenCountEstimated;
		let promptMessages: IMessage[] = [];
		let currentMessage = message.Parent;
		while (currentMessage !== null &&
			promptTokens < this._targetPromptTokenCount)
		{
			// All previous messages should have a known token count
			assert(currentMessage.MessageTokenCountEstimated !== -1);

			// If adding the current message would exceed the target token count,
			//   stop adding messages
			const newTokenCount = promptTokens +
				currentMessage.MessageTokenCountEstimated;
			if (newTokenCount > this._targetPromptTokenCount)
			{
				break;
			}

			promptTokens = newTokenCount;
			promptMessages.push(currentMessage);
			currentMessage = currentMessage.Parent;
		}

		// Create the prompt
		const prompt: IPrompt = {
			History: promptMessages.reverse(),
			Message: message,
			ApiKey: this._apiKeyProvider.ApiKeyRaw,
		};

		// Send the prompt to the LLM
		this._onMessageSent.dispatch(this, message);
		const responses = await this._llm.SendPrompt(prompt);

		// Convert the response from the LLM into a message
		// If the LLM returned multiple responses, ignore all other messages
		//   since this class represents a linear conversation
		assert(responses.length > 0, "LLM returned no responses");
		const response = responses[0];
		message.MessageTokenCountActual = response.PromptTokens;
		const responseMessage = new LlmMessage(
			message,
			response.Contents,
			response.ResponseTokens
		);

		// Update the current leaf message
		this._currentLeafMessage = responseMessage;

		// Broadcast the response received event
		this._onResponseReceived.dispatch(this, responseMessage);

		return responseMessage;
	}

	/// Calculates the cost of the conversation by walking up the conversation.
	private CalcCost(rates: Map<ERole, number>): number
	{
		let cost = 0;
		let currentMessage: IMessage | null = this._currentLeafMessage;
		while (currentMessage !== null)
		{
			let rate = rates.get(currentMessage.Role);
			assert(rate !== undefined, "Unknown message role");

			// All messages that have been added to the conversation should have
			//   a known token count
			assert(currentMessage.MessageTokenCountActual !== -1);
			cost += currentMessage.MessageTokenCountActual * rate;
			currentMessage = currentMessage.Parent;
		}

		return cost;
	}
}
